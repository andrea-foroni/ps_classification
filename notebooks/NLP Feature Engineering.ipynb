{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation, whitespace\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pattern.it import parse, split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load clinical diaries\n",
    "df =pd.read_excel('C:/Users/andrea.foroni/Downloads/DATI PS 2020-CON NOTE DIARIO CLINICO.xlsx')#,usecols=\"A:C,E:F\")\n",
    "df = df.rename(columns={\"MEDICO\" : \"AUTORE\"})\n",
    "\n",
    "df =df.append(pd.read_excel('C:/Users/andrea.foroni/Downloads/DATI PS 2019-CON NOTE DIARIO CLINICO.xlsx'), ignore_index=True)\n",
    "\n",
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_pratica</th>\n",
       "      <th>tipo_nota</th>\n",
       "      <th>data_inserimento</th>\n",
       "      <th>testo</th>\n",
       "      <th>autore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS2019071726</td>\n",
       "      <td>Nota clinica</td>\n",
       "      <td>04/12/2019 12:21:50,759000</td>\n",
       "      <td>si esegue rx endorale che evidenzia la presenz...</td>\n",
       "      <td>DR. TAROZZI MARCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS2020000210</td>\n",
       "      <td>Nota clinica</td>\n",
       "      <td>02/01/2020 09:52:44,668000</td>\n",
       "      <td>Previo consenso informato e previa anestesia p...</td>\n",
       "      <td>DR. FERRANDO CESARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS2020000211</td>\n",
       "      <td>Nota clinica</td>\n",
       "      <td>02/01/2020 09:30:43,247000</td>\n",
       "      <td>presa visione della opt portata dal pz, previo...</td>\n",
       "      <td>DR. FERRANDO CESARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS2020000214</td>\n",
       "      <td>Nota clinica</td>\n",
       "      <td>02/01/2020 11:00:29,157000</td>\n",
       "      <td>Si esegue rx endorale che conferma presenza di...</td>\n",
       "      <td>DR. FERRANDO CESARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS2020000216</td>\n",
       "      <td>Nota clinica</td>\n",
       "      <td>02/01/2020 09:31:38,871000</td>\n",
       "      <td>In accordo con il pz si procede alla ricementa...</td>\n",
       "      <td>DR. FERRANDO CESARE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numero_pratica     tipo_nota            data_inserimento  \\\n",
       "0   PS2019071726  Nota clinica  04/12/2019 12:21:50,759000   \n",
       "1   PS2020000210  Nota clinica  02/01/2020 09:52:44,668000   \n",
       "2   PS2020000211  Nota clinica  02/01/2020 09:30:43,247000   \n",
       "3   PS2020000214  Nota clinica  02/01/2020 11:00:29,157000   \n",
       "4   PS2020000216  Nota clinica  02/01/2020 09:31:38,871000   \n",
       "\n",
       "                                               testo                autore  \n",
       "0  si esegue rx endorale che evidenzia la presenz...    DR. TAROZZI MARCO   \n",
       "1  Previo consenso informato e previa anestesia p...  DR. FERRANDO CESARE   \n",
       "2  presa visione della opt portata dal pz, previo...  DR. FERRANDO CESARE   \n",
       "3  Si esegue rx endorale che conferma presenza di...  DR. FERRANDO CESARE   \n",
       "4  In accordo con il pz si procede alla ricementa...  DR. FERRANDO CESARE   "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8383, 5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_pratica      object\n",
       "tipo_nota           object\n",
       "data_inserimento    object\n",
       "testo               object\n",
       "autore              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatypes\n",
    "df['testo']= df['testo'].astype(str)\n",
    "df['numero_pratica']= df['numero_pratica'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df = df.groupby(['numero_pratica'], as_index = False).agg({'testo': ' '.join})\n",
    "\n",
    "df = df[df['numero_pratica'] !='NUMERO_PRATICA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PS2019020546    1\n",
       "PS2019065962    1\n",
       "PS2019059917    1\n",
       "PS2019045544    1\n",
       "PS2020003411    1\n",
       "               ..\n",
       "PS2019054052    1\n",
       "PS2019058620    1\n",
       "PS2019035413    1\n",
       "PS2019029334    1\n",
       "PS2020015980    1\n",
       "Name: numero_pratica, Length: 8163, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['numero_pratica'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text cleaning and preparation\n",
    "\n",
    "### 1.1. Special character and punctuation signs cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special characters (more than in punctuation list)\n",
    "df['testo_clean'] = df['testo'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whitespaces cleaning\n",
    "\n",
    "whites = list(set(whitespace)-{' '})\n",
    "for w in whites:\n",
    "    df['testo_clean']= df['testo_clean'].str.replace(w,' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Upcase/downcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['testo_clean'] = df['testo_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Import stopwords\n",
    "stop = stopwords.words('italian')\n",
    "\n",
    "for s in stop:\n",
    "    df['testo_clean']= df['testo_clean'].str.replace(r\"\\b\" + s + r\"\\b\",' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Remove double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove double spaces\n",
    "df['testo_clean'] = df['testo_clean'].apply(lambda x: re.sub(' +', ' ', x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Lemmatization\n",
    "\n",
    "I chose to apply lemmatization only as I did not want to produce words that do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize word function\n",
    "def lemmatize_word(input_word):\n",
    "    in_word = input_word#.decode('utf-8')\n",
    "    # print('Something: {}'.format(in_word))\n",
    "    word_it = parse(\n",
    "        in_word,\n",
    "        tokenize=False,\n",
    "        tag=False,\n",
    "        chunk=False,\n",
    "        lemmata=True\n",
    "    )\n",
    "    # print(\"Input: {} Output: {}\".format(in_word, word_it))\n",
    "    the_lemmatized_word = word_it.split()[0][0][4]\n",
    "    # print(\"Returning: {}\".format(the_lemmatized_word))\n",
    "    return the_lemmatized_word\n",
    "\n",
    "#tokenize sentence (string) \n",
    "def tokenize(sentence_totoken):\n",
    "    return nltk.tokenize.word_tokenize(sentence_totoken)\n",
    "    \n",
    "#tokenize and lemmatize sentences and return string\n",
    "def lemmatize_sentence(sentence):\n",
    "    lemmatized = []\n",
    "    for word in tokenize(sentence):\n",
    "        lemmatized.append(lemmatize_word(word))\n",
    "    lemmatized_text = \" \".join(lemmatized)\n",
    "    return lemmatized_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['testo_clean'] = df['testo_clean'].apply(lambda x : lemmatize_sentence(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_pratica</th>\n",
       "      <th>testo</th>\n",
       "      <th>testo_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS2019000196</td>\n",
       "      <td>Si esegue Rx endorale da cui si evidenzia cari...</td>\n",
       "      <td>eseguire rx endorala evidenziare carie mesiala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PS2019000197</td>\n",
       "      <td>si esegue rx endorale di controllo. Si spiega ...</td>\n",
       "      <td>eseguire rx endorala controllo spiegare pazien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS2019000198</td>\n",
       "      <td>eseguita rx endorale che conferma quadro clini...</td>\n",
       "      <td>eseguitare rx endorala conferma quadro clinico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS2019000199</td>\n",
       "      <td>Eseguita rx endorale che evidenzia estensione ...</td>\n",
       "      <td>eseguitare rx endorala evidenziare estensione ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PS2019000200</td>\n",
       "      <td>Si eseguono rx endorali che non evidenziano ri...</td>\n",
       "      <td>eseguire rx endorale evidenziare rima frattura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numero_pratica                                              testo  \\\n",
       "1   PS2019000196  Si esegue Rx endorale da cui si evidenzia cari...   \n",
       "2   PS2019000197  si esegue rx endorale di controllo. Si spiega ...   \n",
       "3   PS2019000198  eseguita rx endorale che conferma quadro clini...   \n",
       "4   PS2019000199  Eseguita rx endorale che evidenzia estensione ...   \n",
       "5   PS2019000200  Si eseguono rx endorali che non evidenziano ri...   \n",
       "\n",
       "                                         testo_clean  \n",
       "1  eseguire rx endorala evidenziare carie mesiala...  \n",
       "2  eseguire rx endorala controllo spiegare pazien...  \n",
       "3  eseguitare rx endorala conferma quadro clinico...  \n",
       "4  eseguitare rx endorala evidenziare estensione ...  \n",
       "5  eseguire rx endorale evidenziare rima frattura...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load categorized and uncategorized \n",
    "df_classified =pd.read_excel('C:/Users/andrea.foroni/Downloads/Odontoiatria PS 2019-2020_21-02_05-05.xlsx',sheet_name= 'Data Base')\n",
    "df_classified.columns = map(str.lower, df_classified.columns)\n",
    "\n",
    "df_classified.head()\n",
    "\n",
    "db_originale=pd.read_excel('C:/Users/andrea.foroni/Downloads/Odontoiatria PS 2019-2020_21-02_05-05.xlsx',sheet_name= 'Data Base')\n",
    "db_originale.columns = map(str.lower, db_originale.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 21)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only relevant columns\n",
    "df_classified= df_classified[['anno', 'mese', 'data_accettazione', 'modalita_dimissione', 'numero_sdo_ricetta', 'eta_pz', 'adulti-bambini', 'data_ora_ingresso_ps', 'data_ora_uscita_ps', 'diagnosi_principale', 'diagnosi_1', 'pz_raggruppamento_residenza']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates and reindex\n",
    "df_classified = df_classified.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosi_principale</th>\n",
       "      <th>motivo_accesso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V722 - VISITA ODONTOIATRICA</td>\n",
       "      <td>VISITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V6759 - ALTRA VISITA DI CONTROLLO</td>\n",
       "      <td>VISITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V523 - COLLOCAZIONE E SISTEMAZIONE DI PROTESI ...</td>\n",
       "      <td>ALTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5206 - DISTURBI DELLERUZIONE DEL DENTE</td>\n",
       "      <td>ALTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52879 - ALTRI DISTURBI DELLEPITELIO ORALE, INC...</td>\n",
       "      <td>ALTRO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 diagnosi_principale motivo_accesso\n",
       "0                        V722 - VISITA ODONTOIATRICA         VISITA\n",
       "1                  V6759 - ALTRA VISITA DI CONTROLLO         VISITA\n",
       "2  V523 - COLLOCAZIONE E SISTEMAZIONE DI PROTESI ...          ALTRO\n",
       "3             5206 - DISTURBI DELLERUZIONE DEL DENTE          ALTRO\n",
       "4  52879 - ALTRI DISTURBI DELLEPITELIO ORALE, INC...          ALTRO"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load aggregated diagnosis\n",
    "diagnosi_aggr=pd.read_excel('C:/Users/andrea.foroni/Downloads/diagnosi_aggr.xlsx')\n",
    "diagnosi_aggr.columns = map(str.lower, diagnosi_aggr.columns)\n",
    "\n",
    "diagnosi_aggr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2252, 13)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join full database with aggregated diagnosis\n",
    "\n",
    "df_classified = df_classified.merge(diagnosi_aggr,how='left',left_on='diagnosi_principale', right_on='diagnosi_principale')\n",
    "df_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join full database with clinical diary\n",
    "\n",
    "df_classified = df_classified.merge(df,how='left',left_on='numero_sdo_ricetta', right_on='numero_pratica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anno</th>\n",
       "      <th>mese</th>\n",
       "      <th>data_accettazione</th>\n",
       "      <th>modalita_dimissione</th>\n",
       "      <th>numero_sdo_ricetta</th>\n",
       "      <th>eta_pz</th>\n",
       "      <th>adulti-bambini</th>\n",
       "      <th>data_ora_ingresso_ps</th>\n",
       "      <th>data_ora_uscita_ps</th>\n",
       "      <th>diagnosi_principale</th>\n",
       "      <th>diagnosi_1</th>\n",
       "      <th>pz_raggruppamento_residenza</th>\n",
       "      <th>motivo_accesso</th>\n",
       "      <th>numero_pratica</th>\n",
       "      <th>testo</th>\n",
       "      <th>testo_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>1 - Dimissione ordinaria al domicilio del pazi...</td>\n",
       "      <td>PS2019011263</td>\n",
       "      <td>24</td>\n",
       "      <td>ADULTO</td>\n",
       "      <td>2019-02-21 08:52:58</td>\n",
       "      <td>2019-02-21 10:00:00</td>\n",
       "      <td>5253 - RADICE DENTARIA RITENUTA</td>\n",
       "      <td>5253 - RADICE DENTARIA RITENUTA</td>\n",
       "      <td>1 - IN ASL</td>\n",
       "      <td>ALTRO</td>\n",
       "      <td>PS2019011263</td>\n",
       "      <td>pz in ps per algia I quadrante.All'eo evidenzi...</td>\n",
       "      <td>pz ps algia quadrante eo evidenziare residuo r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>1 - Dimissione ordinaria al domicilio del pazi...</td>\n",
       "      <td>PS2019011267</td>\n",
       "      <td>44</td>\n",
       "      <td>ADULTO</td>\n",
       "      <td>2019-02-21 08:59:37</td>\n",
       "      <td>2019-02-21 09:23:00</td>\n",
       "      <td>V722 - VISITA ODONTOIATRICA</td>\n",
       "      <td>V722 - VISITA ODONTOIATRICA</td>\n",
       "      <td>1 - IN ASL</td>\n",
       "      <td>VISITA</td>\n",
       "      <td>PS2019011267</td>\n",
       "      <td>Consultata opt eseguita durante accesso in ps ...</td>\n",
       "      <td>consultatare opt eseguitare durante accesso ps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>1 - Dimissione ordinaria al domicilio del pazi...</td>\n",
       "      <td>PS2019011268</td>\n",
       "      <td>28</td>\n",
       "      <td>ADULTO</td>\n",
       "      <td>2019-02-21 09:02:33</td>\n",
       "      <td>2019-02-21 10:02:00</td>\n",
       "      <td>52102 - CARIE DENTALE ESTESA ALLA DENTINA</td>\n",
       "      <td>52102 - CARIE DENTALE ESTESA ALLA DENTINA</td>\n",
       "      <td>1 - IN ASL</td>\n",
       "      <td>CARIE</td>\n",
       "      <td>PS2019011268</td>\n",
       "      <td>eseguita OPT dalla quale si evidenzia vicinanz...</td>\n",
       "      <td>eseguitare opt evidenziare vicinanza nare rima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>1 - Dimissione ordinaria al domicilio del pazi...</td>\n",
       "      <td>PS2019011281</td>\n",
       "      <td>32</td>\n",
       "      <td>ADULTO</td>\n",
       "      <td>2019-02-21 09:37:42</td>\n",
       "      <td>2019-02-21 11:17:00</td>\n",
       "      <td>5253 - RADICE DENTARIA RITENUTA</td>\n",
       "      <td>5253 - RADICE DENTARIA RITENUTA</td>\n",
       "      <td>2 - IN REGIONE</td>\n",
       "      <td>ALTRO</td>\n",
       "      <td>PS2019011281</td>\n",
       "      <td>Eseguita rx endorale che conferma diagnosi cli...</td>\n",
       "      <td>eseguitare rx endorala conferma diagnosi clini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>1 - Dimissione ordinaria al domicilio del pazi...</td>\n",
       "      <td>PS2019011283</td>\n",
       "      <td>66</td>\n",
       "      <td>ADULTO</td>\n",
       "      <td>2019-02-21 09:53:29</td>\n",
       "      <td>2019-02-21 10:44:00</td>\n",
       "      <td>52109 - CARIE DENTALE</td>\n",
       "      <td>52109 - CARIE DENTALE</td>\n",
       "      <td>1 - IN ASL</td>\n",
       "      <td>CARIE</td>\n",
       "      <td>PS2019011283</td>\n",
       "      <td>eseguita rx endorale II q. si evidenzia lesion...</td>\n",
       "      <td>eseguitare rx endorala ii q evidenziare lesion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anno  mese data_accettazione  \\\n",
       "0  2019     2        2019-02-21   \n",
       "1  2019     2        2019-02-21   \n",
       "2  2019     2        2019-02-21   \n",
       "3  2019     2        2019-02-21   \n",
       "4  2019     2        2019-02-21   \n",
       "\n",
       "                                 modalita_dimissione numero_sdo_ricetta  \\\n",
       "0  1 - Dimissione ordinaria al domicilio del pazi...       PS2019011263   \n",
       "1  1 - Dimissione ordinaria al domicilio del pazi...       PS2019011267   \n",
       "2  1 - Dimissione ordinaria al domicilio del pazi...       PS2019011268   \n",
       "3  1 - Dimissione ordinaria al domicilio del pazi...       PS2019011281   \n",
       "4  1 - Dimissione ordinaria al domicilio del pazi...       PS2019011283   \n",
       "\n",
       "   eta_pz adulti-bambini data_ora_ingresso_ps  data_ora_uscita_ps  \\\n",
       "0      24         ADULTO  2019-02-21 08:52:58 2019-02-21 10:00:00   \n",
       "1      44         ADULTO  2019-02-21 08:59:37 2019-02-21 09:23:00   \n",
       "2      28         ADULTO  2019-02-21 09:02:33 2019-02-21 10:02:00   \n",
       "3      32         ADULTO  2019-02-21 09:37:42 2019-02-21 11:17:00   \n",
       "4      66         ADULTO  2019-02-21 09:53:29 2019-02-21 10:44:00   \n",
       "\n",
       "                         diagnosi_principale  \\\n",
       "0            5253 - RADICE DENTARIA RITENUTA   \n",
       "1                V722 - VISITA ODONTOIATRICA   \n",
       "2  52102 - CARIE DENTALE ESTESA ALLA DENTINA   \n",
       "3            5253 - RADICE DENTARIA RITENUTA   \n",
       "4                      52109 - CARIE DENTALE   \n",
       "\n",
       "                                  diagnosi_1 pz_raggruppamento_residenza  \\\n",
       "0            5253 - RADICE DENTARIA RITENUTA                  1 - IN ASL   \n",
       "1                V722 - VISITA ODONTOIATRICA                  1 - IN ASL   \n",
       "2  52102 - CARIE DENTALE ESTESA ALLA DENTINA                  1 - IN ASL   \n",
       "3            5253 - RADICE DENTARIA RITENUTA              2 - IN REGIONE   \n",
       "4                      52109 - CARIE DENTALE                  1 - IN ASL   \n",
       "\n",
       "  motivo_accesso numero_pratica  \\\n",
       "0          ALTRO   PS2019011263   \n",
       "1         VISITA   PS2019011267   \n",
       "2          CARIE   PS2019011268   \n",
       "3          ALTRO   PS2019011281   \n",
       "4          CARIE   PS2019011283   \n",
       "\n",
       "                                               testo  \\\n",
       "0  pz in ps per algia I quadrante.All'eo evidenzi...   \n",
       "1  Consultata opt eseguita durante accesso in ps ...   \n",
       "2  eseguita OPT dalla quale si evidenzia vicinanz...   \n",
       "3  Eseguita rx endorale che conferma diagnosi cli...   \n",
       "4  eseguita rx endorale II q. si evidenzia lesion...   \n",
       "\n",
       "                                         testo_clean  \n",
       "0  pz ps algia quadrante eo evidenziare residuo r...  \n",
       "1  consultatare opt eseguitare durante accesso ps...  \n",
       "2  eseguitare opt evidenziare vicinanza nare rima...  \n",
       "3  eseguitare rx endorala conferma diagnosi clini...  \n",
       "4  eseguitare rx endorala ii q evidenziare lesion...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anno                                    int64\n",
       "mese                                    int64\n",
       "data_accettazione              datetime64[ns]\n",
       "modalita_dimissione                    object\n",
       "numero_sdo_ricetta                     object\n",
       "eta_pz                                  int64\n",
       "adulti-bambini                         object\n",
       "data_ora_ingresso_ps           datetime64[ns]\n",
       "data_ora_uscita_ps             datetime64[ns]\n",
       "diagnosi_principale                    object\n",
       "diagnosi_1                             object\n",
       "pz_raggruppamento_residenza            object\n",
       "motivo_accesso                         object\n",
       "numero_pratica                         object\n",
       "testo                                  object\n",
       "testo_clean                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2252, 16)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V722 - VISITA ODONTOIATRICA                       501\n",
       "52100 - CARIE DENTALE NON SPECIFICATA             249\n",
       "5226 - PERIODONTITE CRONICA APICALE               184\n",
       "52109 - CARIE DENTALE                             157\n",
       "68100 - FLEMMONE E ASCESSO,NON SPECIFICATO        156\n",
       "                                                 ... \n",
       "3501 - NEVRALGIA DEL TRIGEMINO                      1\n",
       "72885 - CONTRATTURA MUSCOLARE                       1\n",
       "52104 - CARIE DENTALE ARRESTATA                     1\n",
       "52332 - PERIODONTITE AGGRESSIVA, GENERALIZZATA      1\n",
       "118 - MICOSI DA PATOGENI FACOLTATIVI                1\n",
       "Name: diagnosi_principale, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified['diagnosi_principale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CARIE             0.279301\n",
       "VISITA            0.237713\n",
       "ASCESSO           0.210302\n",
       "PARODONTOPATIE    0.175803\n",
       "ALTRO             0.058601\n",
       "TRAUMA            0.035917\n",
       "ATM               0.002363\n",
       "Name: motivo_accesso, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified['motivo_accesso'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARIE è il motivo di accesso principale, pari al 27%. Baseline classifier che assegna sempre CARIE come motivo di accesso a PS è accurato al 27%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "accesso_codes = {\n",
    "    'ALTRO': 0,\n",
    "    'ASCESSO': 1,\n",
    "    'ATM': 2,\n",
    "    'CARIE': 3,\n",
    "    'PARODONTOPATIE': 4,\n",
    "    'TRAUMA':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df_classified['accesso_code'] = df_classified['motivo_accesso']\n",
    "df_classified = df_classified.replace({'accesso_code':accesso_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file with uncategorized data\n",
    "df_toclassify = df_classified[np.logical_or(df_classified['accesso_code']=='VISITA' , df_classified['accesso_code'].isnull())]\n",
    "\n",
    "df_toclassify.to_csv('C:/Users/andrea.foroni/Downloads/visite.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove visita\n",
    "\n",
    "df_classified = df_classified[df_classified['accesso_code']!='VISITA']\n",
    "df_classified = df_classified[df_classified['accesso_code'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1613, 17)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anno                                    int64\n",
       "mese                                    int64\n",
       "data_accettazione              datetime64[ns]\n",
       "modalita_dimissione                    object\n",
       "numero_sdo_ricetta                     object\n",
       "eta_pz                                  int64\n",
       "adulti-bambini                         object\n",
       "data_ora_ingresso_ps           datetime64[ns]\n",
       "data_ora_uscita_ps             datetime64[ns]\n",
       "diagnosi_principale                    object\n",
       "diagnosi_1                             object\n",
       "pz_raggruppamento_residenza            object\n",
       "motivo_accesso                         object\n",
       "numero_pratica                         object\n",
       "testo                                  object\n",
       "testo_clean                            object\n",
       "accesso_code                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classified.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train - test split\n",
    "We'll set apart a test set to prove the quality of our models. We'll do Cross Validation in the train set in order to tune the hyperparameters and then test performance on the unseen data of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_classified['testo_clean'], \n",
    "                                                    df_classified['accesso_code'].astype('int64'), \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 0.01\n",
    "max_df = 1.\n",
    "max_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371, 741)\n",
      "(242, 741)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train.values.astype('U')).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test.values.astype('U')).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'ALTRO' category:\n",
      "  . Most correlated unigrams:\n",
      ". clorexidina\n",
      ". visita\n",
      ". orala\n",
      ". rivalutazione\n",
      ". corona\n",
      "  . Most correlated bigrams:\n",
      ". presso reparto\n",
      ". sciacquo clorexidina\n",
      "\n",
      "# 'ASCESSO' category:\n",
      "  . Most correlated unigrams:\n",
      ". ascessuala\n",
      ". ascesso\n",
      ". ml\n",
      ". drenaggio\n",
      ". ceftriaxona\n",
      "  . Most correlated bigrams:\n",
      ". lesione radiotrasparente\n",
      ". lavaggio ipoclorire\n",
      "\n",
      "# 'ATM' category:\n",
      "  . Most correlated unigrams:\n",
      ". altro\n",
      ". clinico\n",
      ". quadro\n",
      ". 18\n",
      ". assumere\n",
      "  . Most correlated bigrams:\n",
      ". quadro clinico\n",
      ". pz riferire\n",
      "\n",
      "# 'CARIE' category:\n",
      "  . Most correlated unigrams:\n",
      ". cariosa\n",
      ". conservativa\n",
      ". destruente\n",
      ". 75\n",
      ". carie\n",
      "  . Most correlated bigrams:\n",
      ". carie destruente\n",
      ". evidenziare carie\n",
      "\n",
      "# 'PARODONTOPATIE' category:\n",
      "  . Most correlated unigrams:\n",
      ". parodontala\n",
      ". perdita\n",
      ". riassorbimento\n",
      ". supporto\n",
      ". osseo\n",
      "  . Most correlated bigrams:\n",
      ". perdita supporto\n",
      ". riassorbimento osseo\n",
      "\n",
      "# 'TRAUMA' category:\n",
      "  . Most correlated unigrams:\n",
      ". palatala\n",
      ". valutare\n",
      ". frammento\n",
      ". coronala\n",
      ". frattura\n",
      "  . Most correlated bigrams:\n",
      ". eseguire molaggio\n",
      ". eseguire rimozione\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "for motivo_accesso, accesso_code in sorted(accesso_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == accesso_code)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(motivo_accesso))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/df.pickle', 'wb') as output:\n",
    "    pickle.dump(df_classified, output)\n",
    "    \n",
    "# features_train\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('C:/Users/andrea.foroni/Documents/myprojects/NLP/Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
